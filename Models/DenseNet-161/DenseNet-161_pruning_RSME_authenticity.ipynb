{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import densenet161, DenseNet161_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database creations using pytorch Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAuthenticityDataset(Dataset):\n",
    "    \"\"\"Dataset for image quality assessment.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the CSV file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.dir_path = os.path.dirname(csv_file)  # Directory of the CSV file\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of samples in the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx,):\n",
    "        \"\"\"\n",
    "        Retrieves an image and its labels by index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple (image, labels) where:\n",
    "                image (PIL.Image): The image.\n",
    "                labels (torch.Tensor): Tensor containing quality and authenticity scores.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # TODO: to be fixed, right now is folder dependent\n",
    "        img_name = self.data.iloc[idx, 3].replace(\"./\", \"../../\")\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        authenticity = self.data.iloc[idx, 1]  # Authenticity column\n",
    "        labels = torch.tensor([authenticity], dtype=torch.float)\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthenticityPredictor(nn.Module):\n",
    "    def __init__(self, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "        # Load pre-trained DenseNet-161\n",
    "        densenet = densenet161(weights=DenseNet161_Weights.DEFAULT)\n",
    "        \n",
    "        # Freeze backbone if requested\n",
    "        if freeze_backbone:\n",
    "            for param in densenet.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        # Store the features\n",
    "        self.features = densenet.features\n",
    "        \n",
    "        # DenseNet already includes a ReLU and pooling after features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # DenseNet-161's output feature dimension is 2208 instead of 2048\n",
    "        self.regression_head = nn.Sequential(\n",
    "                nn.Linear(2208, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(512, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(128, 1)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        predictions = self.regression_head(x)\n",
    "        return predictions, x  # Return predictions and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model(model, dataloader, criterion, device='cuda'):\n",
    "\n",
    "    \"\"\"\n",
    "    Tests the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        dataloader (DataLoader): The test data loader.\n",
    "        criterion (nn.Module): The loss function.\n",
    "        device (str): Device to use for testing ('cuda' or 'cpu'). Defaults to 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss on the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs, _ = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    mse_test_loss = running_loss / len(dataloader.dataset)\n",
    "    rmse_test_loss = np.sqrt(mse_test_loss)\n",
    "\n",
    "    test_loss = rmse_test_loss  # or mse_test_loss, depending on your preference\n",
    "\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def compute_feature_map_importance(model, dataloader, device, layer_name) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Computes the importance of each feature map in a convolution\n",
    "    layer by measuring the change in predictions when the feature map is zero\n",
    "    out.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (indices, importance_scores) where both are numpy arrays\n",
    "    \"\"\"\n",
    "    #if importance_scores.npy exists, load it\n",
    "    if os.path.exists('Ranking_arrays/real_authenticity_batch_importance_scores.npy'):\n",
    "        print(\"Importance scores already computed, loading from file\")\n",
    "        return np.load('Ranking_arrays/real_authenticity_batch_importance_scores.npy')\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    importance_scores = []\n",
    "    dict_modules = dict(model.named_modules())\n",
    "    layer = dict_modules[layer_name]\n",
    "    baseline_authenticity_rmse = test_model(model, dataloader, nn.MSELoss(), device=device)\n",
    "\n",
    "\n",
    "    print(f'Authenticity baseline RMSE: {baseline_authenticity_rmse:.4f}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(layer.out_channels), desc=f\"Computing importance for {layer_name}\"):\n",
    "            # Create a backup of the weights and bias\n",
    "            backup_weights = layer.weight[i, ...].clone()\n",
    "            backup_bias = layer.bias[i].clone() if layer.bias is not None else None\n",
    "\n",
    "            # Zero out the i-th output channel\n",
    "            layer.weight[i, ...] = 0\n",
    "            if layer.bias is not None:\n",
    "                layer.bias[i] = 0\n",
    "\n",
    "\n",
    "            pruned_authenticity_rmse = test_model(model, dataloader, nn.MSELoss(), device=device)\n",
    "\n",
    "\n",
    "            # Compute importance score\n",
    "            importance_score = baseline_authenticity_rmse - pruned_authenticity_rmse\n",
    "            importance_scores.append([i, importance_score])\n",
    "\n",
    "            # After computing importance, restore weights and bias\n",
    "            layer.weight[i, ...] = backup_weights\n",
    "            if layer.bias is not None:\n",
    "                layer.bias[i] = backup_bias\n",
    "\n",
    "    sorted_importance_scores = sorted(importance_scores, key=lambda x: x[1], reverse=True)\n",
    "    # save np array\n",
    "    np.save('Ranking_arrays/real_authenticity_batch_importance_scores.np', sorted_importance_scores)\n",
    "    return np.array(sorted_importance_scores)\n",
    "\n",
    "def remove_noisy_feature_maps(model, dataloader, device, layer_name, sorted_importance_scores, model_path='Weights/pruned_model.pth'):\n",
    "    \"\"\"\n",
    "    Remove noisy feature maps from a convolutional layer based on importance scores.\n",
    "    Feature maps are zeroed out one by one and kept zeroed only if model performance improves.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        dataloader: DataLoader for evaluation\n",
    "        device: Device to run the model on (cuda/cpu)\n",
    "        layer_name: Name of the layer to optimize\n",
    "        sorted_importance_scores: List of tuples (channel_index, importance_score) sorted by importance\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with pruning results and performance metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Get the target layer\n",
    "    dict_modules = dict(model.named_modules())\n",
    "    layer = dict_modules[layer_name]\n",
    "\n",
    "    # Create a backup of the original weights and bias\n",
    "    original_weights = layer.weight.clone()\n",
    "    original_bias = layer.bias.clone() if layer.bias is not None else None\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    removed_features = []\n",
    "    rmse_history = []\n",
    "\n",
    "    # Get baseline performance\n",
    "    baseline_authenticity_rmse = test_model(model, dataloader, nn.MSELoss(), device=device)\n",
    "\n",
    "\n",
    "    print(f\"Baseline authenticity RMSE: {baseline_authenticity_rmse:.4f}\")\n",
    "    print(\"------------------\")\n",
    "\n",
    "    # Track initial performance\n",
    "    rmse_history.append(([], baseline_authenticity_rmse))\n",
    "    baseline_rmse = baseline_authenticity_rmse\n",
    "\n",
    "    # Iterate over the sorted indices and if removing a feature map improves performance, keep it removed\n",
    "    for idx, (channel_idx, importance_score) in tqdm(enumerate(sorted_importance_scores), total=len(sorted_importance_scores), desc=f\"Removing noisy features from {layer_name}\"):\n",
    "        channel_idx = int(channel_idx)\n",
    "\n",
    "        # Temporarily zero out this feature map\n",
    "        layer.weight[channel_idx, ...] = 0\n",
    "        if layer.bias is not None:\n",
    "            layer.bias[channel_idx] = 0\n",
    "\n",
    "        # Evaluate model with feature map removed\n",
    "\n",
    "        authenticity_pruned_rmse = test_model(model, dataloader, nn.MSELoss(), device=device)\n",
    "\n",
    "        print(f\"Iteration {idx+1}/{len(sorted_importance_scores)}: \" +\n",
    "              f\"Testing removal of channel {channel_idx}, \" +\n",
    "              f\"Importance: {importance_score:.4f}, \" +\n",
    "              f\"RMSE: {authenticity_pruned_rmse:.4f}\")\n",
    "\n",
    "        # Decide whether to keep this feature map removed\n",
    "        if authenticity_pruned_rmse < baseline_rmse:\n",
    "            baseline_rmse = authenticity_pruned_rmse # Update baseline RMSE\n",
    "            removed_features.append(channel_idx)\n",
    "            rmse_history.append((removed_features.copy(), baseline_rmse))\n",
    "            print(f\"  ✓ IMPROVING: Zeroing out feature map {channel_idx}\")\n",
    "        else:\n",
    "            # Restore the feature map\n",
    "            layer.weight[channel_idx, ...] = original_weights[channel_idx, ...]\n",
    "            if layer.bias is not None:\n",
    "                layer.bias[channel_idx] = original_bias[channel_idx]\n",
    "            print(f\"  ✗ NOT IMPROVING: Keeping feature map {channel_idx}\")\n",
    "\n",
    "        print(f\"  Current best RMSE: {baseline_rmse:.4f}\")\n",
    "        print(\"------------------\")\n",
    "\n",
    "    # Final statistics\n",
    "    print(\"\\n------------------\")\n",
    "    print(f\"Final RMSE: {baseline_rmse:.4f} after removing {len(removed_features)} feature maps\")\n",
    "    print(f\"Improvement over baseline: {baseline_authenticity_rmse - baseline_rmse:.4f}\")\n",
    "    print(f\"Feature reduction: {(len(removed_features)/len(sorted_importance_scores))*100:.1f}%\")\n",
    "\n",
    "    # Save the pruned model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    return {\n",
    "        'removed_features': removed_features,\n",
    "        'baseline_rmse': baseline_authenticity_rmse,\n",
    "        'final_rmse': baseline_rmse,\n",
    "        'improvement': baseline_authenticity_rmse - baseline_rmse,\n",
    "        'reduction_percentage': (len(removed_features)/len(sorted_importance_scores))*100,\n",
    "        'rmse_history': rmse_history\n",
    "    }\n",
    "\n",
    "def remove_negative_impact_feature_maps(model, dataloader, device, layer_name, sorted_importance_scores, model_path='Weights/negative_impact_pruned_model.pth'):\n",
    "    \"\"\"\n",
    "    Remove feature maps that have a negative impact on model performance based on importance scores (impotance score > 0).\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        dataloader: DataLoader for evaluation\n",
    "        device: Device to run the model on (cuda/cpu)\n",
    "        layer_name: Name of the layer to optimize\n",
    "        sorted_importance_scores: List of tuples (channel_index, importance_score) sorted by importance\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with pruning results and performance metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Get the target layer\n",
    "    dict_modules = dict(model.named_modules())\n",
    "    layer = dict_modules[layer_name]\n",
    "\n",
    "    # Create a backup of the original weights and bias\n",
    "    original_weights = layer.weight.clone()\n",
    "    original_bias = layer.bias.clone() if layer.bias is not None else None\n",
    "\n",
    "    # Get baseline performance\n",
    "\n",
    "    authenticity_rmse = test_model(model, dataloader, nn.MSELoss(), device=device)\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    removed_features = []\n",
    "\n",
    "    # Iterate over the sorted indices and zero out all the feature maps that have a negative impact (importance < 0)\n",
    "\n",
    "    for idx, (channel_idx, importance_score) in tqdm(enumerate(sorted_importance_scores), total=len(sorted_importance_scores), desc=f\"Removing negative impact features from {layer_name}\"):\n",
    "        print(f\"Iteration {idx} - Channel {channel_idx}: Importance score: {importance_score:.4f}\")\n",
    "        if importance_score > 0:\n",
    "            channel_idx = int(channel_idx)\n",
    "            layer.weight[channel_idx, ...] = 0\n",
    "            if layer.bias is not None:\n",
    "                layer.bias[channel_idx] = 0\n",
    "            removed_features.append(channel_idx)\n",
    "\n",
    "    # Evaluate model with feature maps removed\n",
    "    new_authenticity_rmse = test_model(model, dataloader, nn.MSELoss(), device=device)\n",
    "\n",
    "    # Save the pruned model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # Restore original weights for future use\n",
    "    layer.weight.data.copy_(original_weights)\n",
    "    if layer.bias is not None:\n",
    "        layer.bias.data.copy_(original_bias)\n",
    "\n",
    "\n",
    "    return {\n",
    "        'removed_features': removed_features,\n",
    "        'baseline_rmse': authenticity_rmse,\n",
    "        'final_rmse': new_authenticity_rmse,\n",
    "        'improvement': authenticity_rmse - new_authenticity_rmse,\n",
    "        'reduction_percentage': (len(removed_features)/len(sorted_importance_scores))*100\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data transformations for the ImageNet dataset\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "annotations_file = '../../Dataset/AIGCIQA2023/real_images_annotations.csv'\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ImageAuthenticityDataset(csv_file=annotations_file, transform=data_transforms)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 64 # Set to 1 for handling individual images\n",
    "EPOCHS = 20\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "# Create a dictionary containing the data loaders\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader,\n",
    "    'test': test_dataloader\n",
    "}\n",
    "\n",
    "model = AuthenticityPredictor()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss (regression)\n",
    "optimizer = optim.Adam(model.regression_head.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3786844/3782981658.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  base_model.load_state_dict(torch.load('Weights/DenseNet-161_real_authenticity_finetuned.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticity baseline RMSE: 4.4782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing importance for features.denseblock4.denselayer24.conv2: 100%|██████████| 48/48 [32:01<00:00, 40.03s/it]\n",
      "/tmp/ipykernel_3786844/3782981658.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  negative_impact_model.load_state_dict(torch.load('Weights/DenseNet-161_real_authenticity_finetuned.pth'))\n",
      "Removing negative impact features from features.denseblock4.denselayer24.conv2: 100%|██████████| 48/48 [00:00<00:00, 44111.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - Channel 7.0: Importance score: 0.1125\n",
      "Iteration 1 - Channel 32.0: Importance score: 0.0933\n",
      "Iteration 2 - Channel 29.0: Importance score: 0.0555\n",
      "Iteration 3 - Channel 11.0: Importance score: 0.0544\n",
      "Iteration 4 - Channel 6.0: Importance score: 0.0459\n",
      "Iteration 5 - Channel 17.0: Importance score: 0.0411\n",
      "Iteration 6 - Channel 21.0: Importance score: 0.0404\n",
      "Iteration 7 - Channel 14.0: Importance score: 0.0384\n",
      "Iteration 8 - Channel 13.0: Importance score: 0.0277\n",
      "Iteration 9 - Channel 47.0: Importance score: 0.0268\n",
      "Iteration 10 - Channel 3.0: Importance score: 0.0188\n",
      "Iteration 11 - Channel 12.0: Importance score: 0.0187\n",
      "Iteration 12 - Channel 23.0: Importance score: 0.0129\n",
      "Iteration 13 - Channel 24.0: Importance score: 0.0097\n",
      "Iteration 14 - Channel 25.0: Importance score: 0.0061\n",
      "Iteration 15 - Channel 36.0: Importance score: 0.0046\n",
      "Iteration 16 - Channel 18.0: Importance score: 0.0040\n",
      "Iteration 17 - Channel 31.0: Importance score: 0.0034\n",
      "Iteration 18 - Channel 19.0: Importance score: 0.0025\n",
      "Iteration 19 - Channel 27.0: Importance score: 0.0006\n",
      "Iteration 20 - Channel 42.0: Importance score: -0.0058\n",
      "Iteration 21 - Channel 22.0: Importance score: -0.0095\n",
      "Iteration 22 - Channel 15.0: Importance score: -0.0105\n",
      "Iteration 23 - Channel 34.0: Importance score: -0.0107\n",
      "Iteration 24 - Channel 43.0: Importance score: -0.0254\n",
      "Iteration 25 - Channel 10.0: Importance score: -0.0260\n",
      "Iteration 26 - Channel 41.0: Importance score: -0.0304\n",
      "Iteration 27 - Channel 30.0: Importance score: -0.0316\n",
      "Iteration 28 - Channel 26.0: Importance score: -0.0321\n",
      "Iteration 29 - Channel 38.0: Importance score: -0.0325\n",
      "Iteration 30 - Channel 2.0: Importance score: -0.0327\n",
      "Iteration 31 - Channel 8.0: Importance score: -0.0335\n",
      "Iteration 32 - Channel 35.0: Importance score: -0.0362\n",
      "Iteration 33 - Channel 1.0: Importance score: -0.0472\n",
      "Iteration 34 - Channel 33.0: Importance score: -0.0546\n",
      "Iteration 35 - Channel 46.0: Importance score: -0.0569\n",
      "Iteration 36 - Channel 5.0: Importance score: -0.0573\n",
      "Iteration 37 - Channel 37.0: Importance score: -0.0636\n",
      "Iteration 38 - Channel 16.0: Importance score: -0.0774\n",
      "Iteration 39 - Channel 9.0: Importance score: -0.0824\n",
      "Iteration 40 - Channel 39.0: Importance score: -0.0836\n",
      "Iteration 41 - Channel 45.0: Importance score: -0.0841\n",
      "Iteration 42 - Channel 28.0: Importance score: -0.0979\n",
      "Iteration 43 - Channel 20.0: Importance score: -0.1175\n",
      "Iteration 44 - Channel 0.0: Importance score: -0.1220\n",
      "Iteration 45 - Channel 4.0: Importance score: -0.1394\n",
      "Iteration 46 - Channel 44.0: Importance score: -0.1818\n",
      "Iteration 47 - Channel 40.0: Importance score: -0.2098\n",
      "{'removed_features': [7, 32, 29, 11, 6, 17, 21, 14, 13, 47, 3, 12, 23, 24, 25, 36, 18, 31, 19, 27], 'baseline_rmse': np.float64(4.478245674267163), 'final_rmse': np.float64(4.0672951703325415), 'improvement': np.float64(0.41095050393462174), 'reduction_percentage': 41.66666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3786844/3782981658.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  noisy_pruning_model.load_state_dict(torch.load('Weights/DenseNet-161_real_authenticity_finetuned.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline authenticity RMSE: 4.4782\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:   2%|▏         | 1/48 [00:38<30:22, 38.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/48: Testing removal of channel 7, Importance: 0.1125, RMSE: 4.3658\n",
      "  ✓ IMPROVING: Zeroing out feature map 7\n",
      "  Current best RMSE: 4.3658\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:   4%|▍         | 2/48 [01:18<30:01, 39.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2/48: Testing removal of channel 32, Importance: 0.0933, RMSE: 4.2829\n",
      "  ✓ IMPROVING: Zeroing out feature map 32\n",
      "  Current best RMSE: 4.2829\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:   6%|▋         | 3/48 [01:55<28:53, 38.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3/48: Testing removal of channel 29, Importance: 0.0555, RMSE: 4.2399\n",
      "  ✓ IMPROVING: Zeroing out feature map 29\n",
      "  Current best RMSE: 4.2399\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:   8%|▊         | 4/48 [02:34<28:16, 38.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4/48: Testing removal of channel 11, Importance: 0.0544, RMSE: 4.2010\n",
      "  ✓ IMPROVING: Zeroing out feature map 11\n",
      "  Current best RMSE: 4.2010\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  10%|█         | 5/48 [03:14<27:56, 38.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5/48: Testing removal of channel 6, Importance: 0.0459, RMSE: 4.1719\n",
      "  ✓ IMPROVING: Zeroing out feature map 6\n",
      "  Current best RMSE: 4.1719\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  12%|█▎        | 6/48 [03:53<27:24, 39.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6/48: Testing removal of channel 17, Importance: 0.0411, RMSE: 4.1461\n",
      "  ✓ IMPROVING: Zeroing out feature map 17\n",
      "  Current best RMSE: 4.1461\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  15%|█▍        | 7/48 [04:36<27:26, 40.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7/48: Testing removal of channel 21, Importance: 0.0404, RMSE: 4.1200\n",
      "  ✓ IMPROVING: Zeroing out feature map 21\n",
      "  Current best RMSE: 4.1200\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  17%|█▋        | 8/48 [05:14<26:20, 39.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8/48: Testing removal of channel 14, Importance: 0.0384, RMSE: 4.1068\n",
      "  ✓ IMPROVING: Zeroing out feature map 14\n",
      "  Current best RMSE: 4.1068\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  19%|█▉        | 9/48 [05:54<25:57, 39.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9/48: Testing removal of channel 13, Importance: 0.0277, RMSE: 4.0945\n",
      "  ✓ IMPROVING: Zeroing out feature map 13\n",
      "  Current best RMSE: 4.0945\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  21%|██        | 10/48 [06:35<25:20, 40.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10/48: Testing removal of channel 47, Importance: 0.0268, RMSE: 4.0827\n",
      "  ✓ IMPROVING: Zeroing out feature map 47\n",
      "  Current best RMSE: 4.0827\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  23%|██▎       | 11/48 [07:15<24:46, 40.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11/48: Testing removal of channel 3, Importance: 0.0188, RMSE: 4.0730\n",
      "  ✓ IMPROVING: Zeroing out feature map 3\n",
      "  Current best RMSE: 4.0730\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  25%|██▌       | 12/48 [07:55<24:05, 40.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12/48: Testing removal of channel 12, Importance: 0.0187, RMSE: 4.0680\n",
      "  ✓ IMPROVING: Zeroing out feature map 12\n",
      "  Current best RMSE: 4.0680\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  27%|██▋       | 13/48 [08:36<23:33, 40.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13/48: Testing removal of channel 23, Importance: 0.0129, RMSE: 4.0665\n",
      "  ✓ IMPROVING: Zeroing out feature map 23\n",
      "  Current best RMSE: 4.0665\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  29%|██▉       | 14/48 [09:17<22:56, 40.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14/48: Testing removal of channel 24, Importance: 0.0097, RMSE: 4.0630\n",
      "  ✓ IMPROVING: Zeroing out feature map 24\n",
      "  Current best RMSE: 4.0630\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  31%|███▏      | 15/48 [09:55<21:49, 39.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15/48: Testing removal of channel 25, Importance: 0.0061, RMSE: 4.0614\n",
      "  ✓ IMPROVING: Zeroing out feature map 25\n",
      "  Current best RMSE: 4.0614\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  33%|███▎      | 16/48 [10:32<20:46, 38.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16/48: Testing removal of channel 36, Importance: 0.0046, RMSE: 4.0628\n",
      "  ✗ NOT IMPROVING: Keeping feature map 36\n",
      "  Current best RMSE: 4.0614\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  35%|███▌      | 17/48 [11:10<19:56, 38.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17/48: Testing removal of channel 18, Importance: 0.0040, RMSE: 4.0618\n",
      "  ✗ NOT IMPROVING: Keeping feature map 18\n",
      "  Current best RMSE: 4.0614\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  38%|███▊      | 18/48 [11:50<19:34, 39.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18/48: Testing removal of channel 31, Importance: 0.0034, RMSE: 4.0605\n",
      "  ✓ IMPROVING: Zeroing out feature map 31\n",
      "  Current best RMSE: 4.0605\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  40%|███▉      | 19/48 [12:29<18:50, 39.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19/48: Testing removal of channel 19, Importance: 0.0025, RMSE: 4.0603\n",
      "  ✓ IMPROVING: Zeroing out feature map 19\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  42%|████▏     | 20/48 [13:10<18:26, 39.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20/48: Testing removal of channel 27, Importance: 0.0006, RMSE: 4.0645\n",
      "  ✗ NOT IMPROVING: Keeping feature map 27\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  44%|████▍     | 21/48 [13:50<17:55, 39.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21/48: Testing removal of channel 42, Importance: -0.0058, RMSE: 4.0620\n",
      "  ✗ NOT IMPROVING: Keeping feature map 42\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  46%|████▌     | 22/48 [14:27<16:56, 39.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22/48: Testing removal of channel 22, Importance: -0.0095, RMSE: 4.0692\n",
      "  ✗ NOT IMPROVING: Keeping feature map 22\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  48%|████▊     | 23/48 [15:06<16:11, 38.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23/48: Testing removal of channel 15, Importance: -0.0105, RMSE: 4.0673\n",
      "  ✗ NOT IMPROVING: Keeping feature map 15\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  50%|█████     | 24/48 [15:46<15:38, 39.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24/48: Testing removal of channel 34, Importance: -0.0107, RMSE: 4.0659\n",
      "  ✗ NOT IMPROVING: Keeping feature map 34\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  52%|█████▏    | 25/48 [16:25<15:04, 39.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25/48: Testing removal of channel 43, Importance: -0.0254, RMSE: 4.0773\n",
      "  ✗ NOT IMPROVING: Keeping feature map 43\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  54%|█████▍    | 26/48 [17:03<14:11, 38.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26/48: Testing removal of channel 10, Importance: -0.0260, RMSE: 4.0691\n",
      "  ✗ NOT IMPROVING: Keeping feature map 10\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  56%|█████▋    | 27/48 [17:42<13:37, 38.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27/48: Testing removal of channel 41, Importance: -0.0304, RMSE: 4.0718\n",
      "  ✗ NOT IMPROVING: Keeping feature map 41\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  58%|█████▊    | 28/48 [18:20<12:53, 38.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28/48: Testing removal of channel 30, Importance: -0.0316, RMSE: 4.0749\n",
      "  ✗ NOT IMPROVING: Keeping feature map 30\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  60%|██████    | 29/48 [18:59<12:13, 38.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29/48: Testing removal of channel 26, Importance: -0.0321, RMSE: 4.0763\n",
      "  ✗ NOT IMPROVING: Keeping feature map 26\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  62%|██████▎   | 30/48 [19:38<11:39, 38.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30/48: Testing removal of channel 38, Importance: -0.0325, RMSE: 4.0744\n",
      "  ✗ NOT IMPROVING: Keeping feature map 38\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  65%|██████▍   | 31/48 [20:17<11:02, 38.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31/48: Testing removal of channel 2, Importance: -0.0327, RMSE: 4.0742\n",
      "  ✗ NOT IMPROVING: Keeping feature map 2\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  67%|██████▋   | 32/48 [20:55<10:19, 38.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32/48: Testing removal of channel 8, Importance: -0.0335, RMSE: 4.0731\n",
      "  ✗ NOT IMPROVING: Keeping feature map 8\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  69%|██████▉   | 33/48 [21:37<09:51, 39.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33/48: Testing removal of channel 35, Importance: -0.0362, RMSE: 4.0750\n",
      "  ✗ NOT IMPROVING: Keeping feature map 35\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  71%|███████   | 34/48 [22:15<09:09, 39.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34/48: Testing removal of channel 1, Importance: -0.0472, RMSE: 4.0856\n",
      "  ✗ NOT IMPROVING: Keeping feature map 1\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  73%|███████▎  | 35/48 [22:56<08:35, 39.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35/48: Testing removal of channel 33, Importance: -0.0546, RMSE: 4.0831\n",
      "  ✗ NOT IMPROVING: Keeping feature map 33\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  75%|███████▌  | 36/48 [23:36<07:55, 39.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36/48: Testing removal of channel 46, Importance: -0.0569, RMSE: 4.0853\n",
      "  ✗ NOT IMPROVING: Keeping feature map 46\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  77%|███████▋  | 37/48 [24:16<07:18, 39.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37/48: Testing removal of channel 5, Importance: -0.0573, RMSE: 4.0828\n",
      "  ✗ NOT IMPROVING: Keeping feature map 5\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  79%|███████▉  | 38/48 [24:59<06:47, 40.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38/48: Testing removal of channel 37, Importance: -0.0636, RMSE: 4.0825\n",
      "  ✗ NOT IMPROVING: Keeping feature map 37\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  81%|████████▏ | 39/48 [25:41<06:12, 41.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39/48: Testing removal of channel 16, Importance: -0.0774, RMSE: 4.0948\n",
      "  ✗ NOT IMPROVING: Keeping feature map 16\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  83%|████████▎ | 40/48 [26:20<05:24, 40.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40/48: Testing removal of channel 9, Importance: -0.0824, RMSE: 4.0994\n",
      "  ✗ NOT IMPROVING: Keeping feature map 9\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  85%|████████▌ | 41/48 [27:02<04:46, 40.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41/48: Testing removal of channel 39, Importance: -0.0836, RMSE: 4.0972\n",
      "  ✗ NOT IMPROVING: Keeping feature map 39\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  88%|████████▊ | 42/48 [27:44<04:07, 41.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42/48: Testing removal of channel 45, Importance: -0.0841, RMSE: 4.0994\n",
      "  ✗ NOT IMPROVING: Keeping feature map 45\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  90%|████████▉ | 43/48 [28:27<03:28, 41.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43/48: Testing removal of channel 28, Importance: -0.0979, RMSE: 4.1017\n",
      "  ✗ NOT IMPROVING: Keeping feature map 28\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  92%|█████████▏| 44/48 [29:07<02:45, 41.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44/48: Testing removal of channel 20, Importance: -0.1175, RMSE: 4.1018\n",
      "  ✗ NOT IMPROVING: Keeping feature map 20\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  94%|█████████▍| 45/48 [29:49<02:04, 41.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45/48: Testing removal of channel 0, Importance: -0.1220, RMSE: 4.1012\n",
      "  ✗ NOT IMPROVING: Keeping feature map 0\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  96%|█████████▌| 46/48 [30:32<01:23, 41.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46/48: Testing removal of channel 4, Importance: -0.1394, RMSE: 4.1297\n",
      "  ✗ NOT IMPROVING: Keeping feature map 4\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2:  98%|█████████▊| 47/48 [31:13<00:41, 41.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47/48: Testing removal of channel 44, Importance: -0.1818, RMSE: 4.1609\n",
      "  ✗ NOT IMPROVING: Keeping feature map 44\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing noisy features from features.denseblock4.denselayer24.conv2: 100%|██████████| 48/48 [31:53<00:00, 39.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48/48: Testing removal of channel 40, Importance: -0.2098, RMSE: 4.1562\n",
      "  ✗ NOT IMPROVING: Keeping feature map 40\n",
      "  Current best RMSE: 4.0603\n",
      "------------------\n",
      "\n",
      "------------------\n",
      "Final RMSE: 4.0603 after removing 17 feature maps\n",
      "Improvement over baseline: 0.4180\n",
      "Feature reduction: 35.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LAYER to prune\n",
    "LAYER = 'features.denseblock4.denselayer24.conv2'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# Base model for importance score computation\n",
    "base_model = AuthenticityPredictor()\n",
    "base_model.load_state_dict(torch.load('Weights/DenseNet-161_real_authenticity_finetuned.pth'))\n",
    "base_model.eval()\n",
    "base_model.to(DEVICE)\n",
    "\n",
    "sorted_importance_scores = compute_feature_map_importance(base_model, train_dataloader, DEVICE, LAYER)\n",
    "np.save('Ranking_arrays/real_authenticity_importance_scores.npy', sorted_importance_scores)\n",
    "del base_model\n",
    "\n",
    "# Model for negative impact feature maps removal\n",
    "negative_impact_model = AuthenticityPredictor()\n",
    "negative_impact_model.load_state_dict(torch.load('Weights/DenseNet-161_real_authenticity_finetuned.pth'))\n",
    "negative_impact_model.eval()\n",
    "negative_impact_model.to(DEVICE)\n",
    "\n",
    "negative_impact_subset = remove_negative_impact_feature_maps(negative_impact_model, train_dataloader, DEVICE, LAYER, sorted_importance_scores, model_path='Weights/real_authenticity_negative_impact_pruned_model.pth')\n",
    "print(negative_impact_subset)\n",
    "\n",
    "del negative_impact_model\n",
    "\n",
    "\n",
    "# Model for noisy feature maps removal\n",
    "noisy_pruning_model = AuthenticityPredictor()\n",
    "noisy_pruning_model.load_state_dict(torch.load('Weights/DenseNet-161_real_authenticity_finetuned.pth'))\n",
    "noisy_pruning_model.eval()\n",
    "noisy_pruning_model.to(DEVICE)\n",
    "\n",
    "noisy_optimal_subset = remove_noisy_feature_maps(noisy_pruning_model, train_dataloader, DEVICE, LAYER, sorted_importance_scores, model_path='Weights/real_authenticity_noise_out_pruned_model.pth')\n",
    "\n",
    "del noisy_pruning_model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
