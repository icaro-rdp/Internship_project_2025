{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first script in the Inception Pipeline. It identifes best features subsets for each of the 6 categories for which we have human judgments. These subsets are later used to produce modified models from which we compute FID and IS scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE-O-gwiQjNp"
   },
   "source": [
    "# 1.Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5vKVbo_QrnF"
   },
   "source": [
    "Useful libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bne-zUwEIMbt"
   },
   "outputs": [],
   "source": [
    "import os # for file handling\n",
    "import torch # for deep learning\n",
    "from PIL import Image # for image handling\n",
    "from torchvision import models, transforms # for pre-trained models\n",
    "import torch.nn as nn # for neural network layers\n",
    "import numpy as np # for numerical operations\n",
    "from scipy.stats import spearmanr # for correlation calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "images_path = f'{os.getcwd()}/Peterson_data/images_by_categories'\n",
    "# print the images in the folder\n",
    "categories = [f for f in os.listdir(images_path) if os.path.isdir(os.path.join(images_path, f))]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checks for CUDA/GPU avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "# Check the number of GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs: {num_gpus}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# Print the CUDA version\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Create a tensor and move it to GPU\n",
    "    tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "    tensor_gpu = tensor.to('cuda')\n",
    "    print(f\"Tensor on GPU: {tensor_gpu}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Tensor cannot be moved to GPU.\")\n",
    "import torch\n",
    "\n",
    "# Check if the installed PyTorch version is compatible with the installed CUDA version\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"cuDNN Version: {torch.backends.cudnn.version()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yRwah-iR2J8"
   },
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQ0NYRvYR00N"
   },
   "outputs": [],
   "source": [
    "def upper_triangle_values(matrix):\n",
    "    \"\"\"\n",
    "    Extracts the upper triangular values from a square matrix, excluding the diagonal.\n",
    "\n",
    "    Args:\n",
    "    matrix (numpy.ndarray): A 2D square numpy array.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 1D numpy array containing the upper triangular values of the input matrix.\n",
    "    \"\"\"\n",
    "    # Extract the upper triangle indices, excluding the diagonal\n",
    "    upper_triangle_indices = np.triu_indices_from(matrix, k=1)\n",
    "    return matrix[upper_triangle_indices]\n",
    "\n",
    "\n",
    "def compute_spearman_uppert(matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Computes the Spearman correlation between the upper triangles of two matrices.\n",
    "\n",
    "    Args:\n",
    "    matrix1 (numpy.ndarray): The first 2D square numpy array.\n",
    "    matrix2 (numpy.ndarray): The second 2D square numpy array.\n",
    "\n",
    "    Returns:\n",
    "    float: The Spearman correlation coefficient between the upper triangles of the input matrices.\n",
    "    \"\"\"\n",
    "    upper_triangle_values1 = upper_triangle_values(matrix1)\n",
    "    upper_triangle_values2 = upper_triangle_values(matrix2)\n",
    "    correlation, _ = spearmanr(upper_triangle_values1, upper_triangle_values2)\n",
    "    return correlation\n",
    "\n",
    "\n",
    "def compute_cosine_similarity_matrix(embeddings):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity matrix for a given array of embeddings.\n",
    "\n",
    "    Args:\n",
    "    embeddings (numpy.ndarray): A 2D numpy array of shape (n_samples, n_features) representing the embeddings.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 2D numpy array of shape (n_samples, n_samples) representing the cosine similarity matrix.\n",
    "    \"\"\"\n",
    "    norms = np.linalg.norm(embeddings, axis=1)\n",
    "    dot_product = np.dot(embeddings, embeddings.T)\n",
    "    similarity_matrix = dot_product / (norms[:, None] * norms[None, :])\n",
    "    return similarity_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJtZnUaL_ioi"
   },
   "source": [
    "# 2.load model and create embmeddings from full model\n",
    "\n",
    "1. SET the category here\n",
    "2. using pool_3 layer for embeddings\n",
    "2.   do not touch the normalization as this is how images are normalized for training inception and has to be kept the same for evaluation of new images\n",
    "3. the model mimicks the inception pipeline but ends it at the pool_3 layer to extract embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjoFOiqiEooa",
    "outputId": "0c71ff1a-2ef1-4c23-f9b5-e3a554803fc6"
   },
   "outputs": [],
   "source": [
    "# Define the category variable: animals, automobiles, furniture, fruits, vegetables, various\n",
    "\n",
    "category = 'vegetables'\n",
    "\n",
    "# Use the category variable in the path and dictionary key\n",
    "\n",
    "\n",
    "\n",
    "# Define a transformation to preprocess the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Resize images to 299x299 for Inception-v3\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n",
    "\n",
    "# In this function, need to sort the filenames to match the human similairty judgments order\n",
    "# get a printout of filenames to make sure these are sorted well\n",
    "def load_images_from_directory(image_dir, transform):\n",
    "    images = []\n",
    "    filenames = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(filenames)\n",
    "    for filename in filenames:\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = transform(image)\n",
    "        images.append(image)\n",
    "    return torch.stack(images)\n",
    "\n",
    "\n",
    "class InceptionV3Pool3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InceptionV3Pool3, self).__init__()\n",
    "        inception = models.inception_v3(pretrained=True)\n",
    "        self.features = nn.Sequential(\n",
    "            inception.Conv2d_1a_3x3,\n",
    "            inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            inception.Conv2d_3b_1x1,\n",
    "            inception.Conv2d_4a_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            inception.Mixed_5b,\n",
    "            inception.Mixed_5c,\n",
    "            inception.Mixed_5d,\n",
    "            inception.Mixed_6a,\n",
    "            inception.Mixed_6b,\n",
    "            inception.Mixed_6c,\n",
    "            inception.Mixed_6d,\n",
    "            inception.Mixed_6e,\n",
    "            inception.Mixed_7a,\n",
    "            inception.Mixed_7b,\n",
    "            inception.Mixed_7c,\n",
    "        )\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "embedding_model = InceptionV3Pool3()\n",
    "embedding_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "# Load images from the directory\n",
    "image_dir = image_dir = f'/home/hasson/data/peterson/{category}/images'\n",
    "images = load_images_from_directory(image_dir, transform)\n",
    "\n",
    "# Move images to the same device as the model (GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "embedding_model.to(device)\n",
    "images = images.to(device)\n",
    "\n",
    "# Disable gradient calculations\n",
    "with torch.no_grad():\n",
    "    embeddings = embedding_model(images)\n",
    "\n",
    "# Move embeddings back to CPU if necessary\n",
    "embeddings = embeddings.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hT2uHLVd_vAD"
   },
   "source": [
    "## Load human sim and compute Baseline correlation\n",
    "\n",
    "Computation of baseline correlation is for sanity.\n",
    "It is also computed in the application of the pruning algorithm itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncqzbrL_JYdI",
    "outputId": "432f7fce-6146-4b02-f5d3-6e4067eb1fb8"
   },
   "outputs": [],
   "source": [
    "# load human sim judg\n",
    "# the npz file is an array that holds similarity judgmetns for all categories\n",
    "hsim = np.load('/home/hasson/data/peterson/hsim_peterson.npz')\n",
    "\n",
    "# e.g. get animals\n",
    "hsim_cat = hsim[category]\n",
    "\n",
    "embeddings_np = embeddings.cpu().numpy()\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = compute_cosine_similarity_matrix(embeddings_np)\n",
    "\n",
    "\n",
    "# Compute the Spearman correlation\n",
    "spearman_corr = compute_spearman_uppert(hsim_cat, similarity_matrix)\n",
    "\n",
    "# Print the Spearman correlation coefficient\n",
    "print(f\"Spearman Correlation: {spearman_corr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dulZWLrndrxU"
   },
   "source": [
    "# 3.Supervised pruning\n",
    "\n",
    "The best_subset is a list of features that will then be used to filter embeddings from inceptionV3 from the human similarity matrices for each category.bold text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6Ms7xJMduD4",
    "outputId": "3e6e45ef-4e0d-4927-994c-d4df55e6c680"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "# Step 1: Compute baseline correlation\n",
    "def compute_baseline_corr(SM_HM, SM_DNN):\n",
    "    # Flatten upper triangle of matrices to 1darray\n",
    "    mask = np.triu(np.ones_like(SM_HM), k=1).astype(bool)\n",
    "    hm_flat = SM_HM[mask]\n",
    "    dnn_flat = SM_DNN[mask]\n",
    "    return spearmanr(hm_flat, dnn_flat)[0]\n",
    "\n",
    "# Step 2: Rank features\n",
    "def rank_features(SM_HM, SM_DNN, full_embeddings):\n",
    "    N = full_embeddings.shape[1]\n",
    "    baseline_corr = compute_baseline_corr(SM_HM, SM_DNN)\n",
    "\n",
    "    feature_importance = []\n",
    "    for i in range(N):\n",
    "        # print(f\"computing feature {i}\")\n",
    "        # Remove feature i\n",
    "        reduced_embeddings = np.delete(full_embeddings, i, axis=1)\n",
    "        # Compute cosine similarity matrix\n",
    "        cosine_sim_matrix = compute_cosine_similarity_matrix(reduced_embeddings)\n",
    "        # Compute correlation with cosine similarity matrix\n",
    "        corr_reduced = compute_corr_upper_triangle(SM_HM, cosine_sim_matrix)\n",
    "        # Calculate difference D; difference in Spearman R\n",
    "        D = baseline_corr - corr_reduced\n",
    "        feature_importance.append((i, D))\n",
    "    # Sort features by importance (D value)\n",
    "    feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    return feature_importance\n",
    "\n",
    "# Function to compute correlation of upper triangle\n",
    "def compute_corr_upper_triangle(mat1, mat2):\n",
    "    mask = np.triu(np.ones_like(mat1), k=1).astype(bool)\n",
    "    mat1_flat = mat1[mask]\n",
    "    mat2_flat = mat2[mask]\n",
    "    return spearmanr(mat1_flat, mat2_flat)[0]\n",
    "\n",
    "# Step 3: Construct pruned embeddings\n",
    "def construct_pruned_embeddings(SM_HM, full_embeddings, feature_importance):\n",
    "    best_corr = -np.inf\n",
    "    best_subset = []\n",
    "\n",
    "    # Iterate over ranked features\n",
    "    for i in range(len(feature_importance)):\n",
    "        # Include features in descending order of importance\n",
    "        features_to_include = [feature_importance[j][0] for j in range(i + 1)]\n",
    "        pruned_embeddings = full_embeddings[:, features_to_include]\n",
    "        cosine_sim_matrix = compute_cosine_similarity_matrix(pruned_embeddings)\n",
    "        # Compute correlation after including selected features\n",
    "        corr = compute_corr_upper_triangle(SM_HM, cosine_sim_matrix)\n",
    "        # Store the maximum correlation and corresponding subset of features\n",
    "        if corr > best_corr:\n",
    "            best_corr = corr\n",
    "            best_subset = features_to_include\n",
    "\n",
    "    return best_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### actual function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6Ms7xJMduD4",
    "outputId": "3e6e45ef-4e0d-4927-994c-d4df55e6c680"
   },
   "outputs": [],
   "source": [
    "SM_HM = hsim_cat\n",
    "SM_DNN = similarity_matrix\n",
    "full_embeddings = embeddings_np\n",
    "\n",
    "# Step 1: Compute baseline correlation\n",
    "baseline_corr = compute_baseline_corr(SM_HM, SM_DNN)\n",
    "print(f\"baseline correlation is {baseline_corr}\")\n",
    "\n",
    "# Step 2: Rank features\n",
    "feature_importance = rank_features(SM_HM,SM_DNN,full_embeddings)\n",
    "\n",
    "# Step 3: Construct pruned embeddings\n",
    "# best_subset is constructed for each category and will be applied to full embeddings\n",
    "# can be saved to google drive to be used in future scripts\n",
    "best_subset = construct_pruned_embeddings(SM_HM, full_embeddings, feature_importance)\n",
    "\n",
    "print(\"Best subset of features:\", best_subset)\n",
    "\n",
    "# Step 4: Evaluate pruned embeddings\n",
    "pruned_embeddings_best = full_embeddings[:, best_subset]\n",
    "best_prune_sim = compute_cosine_similarity_matrix(pruned_embeddings_best)\n",
    "best_cor = compute_corr_upper_triangle(SM_HM, best_prune_sim)\n",
    "\n",
    "baseline_corr = compute_baseline_corr(SM_HM, SM_DNN)\n",
    "print(f\"baseline correlation is {baseline_corr}\")\n",
    "print(\"Best correlation :\", best_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49NouUvYY5bf"
   },
   "source": [
    "## save best subset list to file\n",
    "\n",
    "Make sure to change the path here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzISHoz4XvbI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(best_subset)\n",
    "\n",
    "# Define the file name using the category variable\n",
    "file_name = f\"{category}_bestsubset.csv\"\n",
    "\n",
    "# Save the DataFrame as a CSV file to the specified path\n",
    "df.to_csv(f'/home/hasson/progproj/2024Giulia/pruned_subsets/{file_name}', index=False, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
