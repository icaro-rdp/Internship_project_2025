{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database creations using pytorch Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageQualityDataset(Dataset):\n",
    "    \"\"\"Dataset for image quality assessment.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the CSV file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of samples in the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves an image and its labels by index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple (image, labels) where:\n",
    "                image (PIL.Image): The image.\n",
    "                labels (torch.Tensor): Tensor containing quality labels.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(os.getcwd(), self.data.iloc[idx, 3])  # image_path column\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        quality = self.data.iloc[idx, 0]  # Quality column\n",
    "        labels = torch.tensor([quality], dtype=torch.float)\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityPredictor(nn.Module):\n",
    "    def __init__(self, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "        # Load pre-trained VGG16\n",
    "        vgg = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "        \n",
    "        # Freeze backbone if requested\n",
    "        if freeze_backbone:\n",
    "            for param in vgg.features.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        # Extract features up to fc2\n",
    "        self.features = vgg.features\n",
    "        self.avgpool = vgg.avgpool\n",
    "        self.fc1 = vgg.classifier[:-1]  # Up to fc2 (4096 -> 128)\n",
    "        \n",
    "        # New regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(4096, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 1)  # Predict quality\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        features = self.fc1(x)\n",
    "        predictions = self.regression_head(features)\n",
    "        return predictions, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10, device='cuda'):\n",
    "    \"\"\"\n",
    "    Trains the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        dataloaders (dict): A dictionary containing the training and validation data loaders.\n",
    "        criterion (nn.Module): The loss function.\n",
    "        optimizer (optim.Optimizer): The optimizer.\n",
    "        num_epochs (int): Number of epochs to train for. Defaults to 10.\n",
    "        device (str): Device to use for training ('cuda' or 'cpu'). Defaults to 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: The trained model.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:  # Iterate over training and validation phases\n",
    "            print(f'{phase} phase')\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:  # Iterate over data in the current phase\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):  # Enable gradients only during training\n",
    "                    outputs, _ = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f}') # Print loss for the current phase\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    return model\n",
    "\n",
    "def test_model(model, dataloader, criterion, device='cuda'):\n",
    "\n",
    "    \"\"\"\n",
    "    Tests the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        dataloader (DataLoader): The test data loader.\n",
    "        criterion (nn.Module): The loss function.\n",
    "        device (str): Device to use for testing ('cuda' or 'cpu'). Defaults to 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss on the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs, _ = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    test_loss = running_loss / len(dataloader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    return test_loss\n",
    "\n",
    "def get_predictions(model, dataloader, device)-> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Get predictions from the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        dataloader (DataLoader): The data loader.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple (predictions, labels) where:\n",
    "            predictions (torch.Tensor): Predictions from the model.\n",
    "            labels (torch.Tensor): Ground truth labels.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, target in dataloader:\n",
    "            outputs, _ = model(inputs.to(device))\n",
    "            predictions.append(outputs)\n",
    "            labels.append(target)\n",
    "\n",
    "    #move to cpu and concatenate\n",
    "    predictions = torch.cat(predictions).cpu()\n",
    "    labels = torch.cat(labels).cpu()\n",
    "\n",
    "    return predictions, labels\n",
    "\n",
    "def get_regression_errors(tuple: tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Get regression errors.\n",
    "\n",
    "    Args:\n",
    "        tuple: A tuple (predictions, labels) where:\n",
    "            predictions (torch.Tensor): Predictions from the model.\n",
    "            labels (torch.Tensor): Ground truth labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Regression errors\n",
    "    \"\"\"\n",
    "    predictions, labels = tuple\n",
    "    quality_errors = predictions[:, 0] - labels[:, 0]\n",
    "    return quality_errors\n",
    "\n",
    "def get_rmse(errors: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Get the root mean squared error.\n",
    "\n",
    "    Args:\n",
    "        errors (torch.Tensor): Errors.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Root mean squared error.\n",
    "    \"\"\"\n",
    "    return torch.sqrt(torch.mean(errors ** 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data transformations for the ImageNet dataset\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "annotations_file = 'Dataset/AIGCIQA2023/mos_data.csv'\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ImageQualityDataset(csv_file=annotations_file, transform=data_transforms)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Create a dictionary containing the data loaders\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader,\n",
    "    'test': test_dataloader\n",
    "}\n",
    "\n",
    "model = QualityPredictor()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss (regression)\n",
    "optimizer = optim.Adam(model.regression_head.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 123.0457\n",
      "val phase\n",
      "val Loss: 146.6046\n",
      "Epoch 18/19\n",
      "----------\n",
      "train phase\n",
      "train Loss: 125.9856\n",
      "val phase\n",
      "val Loss: 144.6421\n",
      "Epoch 19/19\n",
      "----------\n",
      "train phase\n",
      "train Loss: 116.9352\n",
      "val phase\n",
      "val Loss: 150.2770\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "quality_predictor_trained= train_model(model, dataloaders, criterion, optimizer, EPOCHS, device)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = 'Models/VGG-16_quality_finetuned.pth'\n",
    "torch.save(quality_predictor_trained.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities for pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature_map_importance(model, dataloader, device, layer_name) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Computes the importance of each feature map in a convolution\n",
    "    layer by measuring the change in predictions when the feature map is zero\n",
    "    out.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (indices, importance_scores) where both are numpy arrays\n",
    "    \"\"\"\n",
    "    #if importance_scores.npy exists, load it\n",
    "    if os.path.exists('Ranking_arrays/quality_importance_scores.npy'):\n",
    "        print(\"Importance scores already computed, loading from file\")\n",
    "        return np.load('Ranking_arrays/quality_importance_scores.npy')\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    importance_scores = []\n",
    "    dict_modules = dict(model.named_modules())\n",
    "    layer = dict_modules[layer_name]\n",
    "    baseline_predictions = get_predictions(model, dataloader, device)\n",
    "    regression_errors = get_regression_errors(baseline_predictions)\n",
    "    baseline_quality_rmse = get_rmse(regression_errors)\n",
    "\n",
    "    \n",
    "    print(f'quality baseline RMSE: {baseline_quality_rmse:.4f}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(layer.out_channels):\n",
    "            # Create a backup of the weights and bias\n",
    "            backup_weights = layer.weight[i, ...].clone()\n",
    "            backup_bias = layer.bias[i].clone() if layer.bias is not None else None\n",
    "\n",
    "            # Zero out the i-th output channel\n",
    "            layer.weight[i, ...] = 0\n",
    "            if layer.bias is not None:\n",
    "                layer.bias[i] = 0\n",
    "\n",
    "            # Get predictions with the pruned feature map\n",
    "            pruned_predictions = get_predictions(model, dataloader, device)\n",
    "            pruned_regression_errors = get_regression_errors(pruned_predictions)\n",
    "            pruned_quality_rmse = get_rmse(pruned_regression_errors)\n",
    "            \n",
    "    \n",
    "            # Compute importance score\n",
    "            importance_score = baseline_quality_rmse - pruned_quality_rmse\n",
    "            importance_scores.append([i, importance_score])\n",
    "            \n",
    "\n",
    "            print(f'Feature map {i}: Importance score: {importance_score:.4f}')\n",
    "            \n",
    "            # After computing importance, restore weights and bias\n",
    "            layer.weight[i, ...] = backup_weights\n",
    "            if layer.bias is not None:\n",
    "                layer.bias[i] = backup_bias \n",
    "\n",
    "    sorted_importance_scores = sorted(importance_scores, key=lambda x: x[1], reverse=True)\n",
    "    # save np array \n",
    "    np.save('quality_importance_scores.np', sorted_importance_scores)\n",
    "    return np.array(sorted_importance_scores)\n",
    "\n",
    "def remove_noisy_feature_maps(model, dataloader, device, layer_name, sorted_importance_scores, model_path='Models/pruned_model.pth'):\n",
    "    \"\"\"\n",
    "    Remove noisy feature maps from a convolutional layer based on importance scores.\n",
    "    Feature maps are zeroed out one by one and kept zeroed only if model performance improves.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        dataloader: DataLoader for evaluation\n",
    "        device: Device to run the model on (cuda/cpu)\n",
    "        layer_name: Name of the layer to optimize\n",
    "        sorted_importance_scores: List of tuples (channel_index, importance_score) sorted by importance\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with pruning results and performance metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Get the target layer\n",
    "    dict_modules = dict(model.named_modules())\n",
    "    layer = dict_modules[layer_name]\n",
    "    \n",
    "    # Create a backup of the original weights and bias\n",
    "    original_weights = layer.weight.clone()\n",
    "    original_bias = layer.bias.clone() if layer.bias is not None else None\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    removed_features = []\n",
    "    rmse_history = []\n",
    "    \n",
    "    # Get baseline performance\n",
    "    baseline_predictions = get_predictions(model, dataloader, device)\n",
    "    baseline_regression_errors = get_regression_errors(baseline_predictions)\n",
    "    baseline_quality_rmse = get_rmse(baseline_regression_errors)\n",
    "    \n",
    "    \n",
    "    print(f\"Baseline quality RMSE: {baseline_quality_rmse:.4f}\")\n",
    "    print(\"------------------\")\n",
    "    \n",
    "    # Track initial performance\n",
    "    rmse_history.append(([], baseline_quality_rmse))\n",
    "    baseline_rmse = baseline_quality_rmse\n",
    "    \n",
    "    # Iterate over the sorted indices and if removing a feature map improves performance, keep it removed\n",
    "    for idx, (channel_idx, importance_score) in enumerate(sorted_importance_scores):\n",
    "        channel_idx = int(channel_idx)\n",
    "        \n",
    "        # Temporarily zero out this feature map\n",
    "        layer.weight[channel_idx, ...] = 0\n",
    "        if layer.bias is not None:\n",
    "            layer.bias[channel_idx] = 0\n",
    "        \n",
    "        # Evaluate model with feature map removed\n",
    "        predictions = get_predictions(model, dataloader, device)\n",
    "        regression_errors = get_regression_errors(predictions)\n",
    "        quality_pruned_rmse = get_rmse(regression_errors)\n",
    "        \n",
    "        print(f\"Iteration {idx+1}/{len(sorted_importance_scores)}: \" +\n",
    "              f\"Testing removal of channel {channel_idx}, \" +\n",
    "              f\"Importance: {importance_score:.4f}, \" +\n",
    "              f\"RMSE: {quality_pruned_rmse:.4f}\")\n",
    "        \n",
    "        # Decide whether to keep this feature map removed\n",
    "        if quality_pruned_rmse < baseline_rmse:\n",
    "            baseline_rmse = quality_pruned_rmse # Update baseline RMSE\n",
    "            removed_features.append(channel_idx)\n",
    "            rmse_history.append((removed_features.copy(), baseline_rmse))\n",
    "            print(f\"  ✓ IMPROVING: Zeroing out feature map {channel_idx}\")\n",
    "        else:\n",
    "            # Restore the feature map\n",
    "            layer.weight[channel_idx, ...] = original_weights[channel_idx, ...]\n",
    "            if layer.bias is not None:\n",
    "                layer.bias[channel_idx] = original_bias[channel_idx]\n",
    "            print(f\"  ✗ NOT IMPROVING: Keeping feature map {channel_idx}\")\n",
    "        \n",
    "        print(f\"  Current best RMSE: {baseline_rmse:.4f}\")\n",
    "        print(\"------------------\")\n",
    "    \n",
    "    # Final statistics\n",
    "    print(\"\\n------------------\")\n",
    "    print(f\"Final RMSE: {baseline_rmse:.4f} after removing {len(removed_features)} feature maps\")\n",
    "    print(f\"Improvement over baseline: {baseline_quality_rmse - baseline_rmse:.4f}\")\n",
    "    print(f\"Feature reduction: {(len(removed_features)/len(sorted_importance_scores))*100:.1f}%\")\n",
    "    \n",
    "    # Save the pruned model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    return {\n",
    "        'removed_features': removed_features,\n",
    "        'baseline_rmse': baseline_quality_rmse,\n",
    "        'final_rmse': baseline_rmse,\n",
    "        'improvement': baseline_quality_rmse - baseline_rmse,\n",
    "        'reduction_percentage': (len(removed_features)/len(sorted_importance_scores))*100,\n",
    "        'rmse_history': rmse_history\n",
    "    }\n",
    "\n",
    "def remove_negative_impact_feature_maps(model, dataloader, device, layer_name, sorted_importance_scores, model_path='Models/negative_impact_pruned_model.pth'):\n",
    "    \"\"\"\n",
    "    Remove feature maps that have a negative impact on model performance based on importance scores (impotance score > 0).\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        dataloader: DataLoader for evaluation\n",
    "        device: Device to run the model on (cuda/cpu)\n",
    "        layer_name: Name of the layer to optimize\n",
    "        sorted_importance_scores: List of tuples (channel_index, importance_score) sorted by importance\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with pruning results and performance metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Get the target layer\n",
    "    dict_modules = dict(model.named_modules())\n",
    "    layer = dict_modules[layer_name]\n",
    "    \n",
    "    # Create a backup of the original weights and bias\n",
    "    original_weights = layer.weight.clone()\n",
    "    original_bias = layer.bias.clone() if layer.bias is not None else None\n",
    "    \n",
    "    # Get baseline performance\n",
    "    predictions = get_predictions(model, dataloader, device)\n",
    "    regression_errors = get_regression_errors(predictions)\n",
    "    quality_rmse = get_rmse(regression_errors)\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    removed_features = []\n",
    "    \n",
    "    # Iterate over the sorted indices and zero out all the feature maps that have a negative impact (importance < 0)\n",
    "\n",
    "    for idx, (channel_idx, importance_score) in enumerate(sorted_importance_scores):\n",
    "        print(f\"Iteration {idx} - Channel {channel_idx}: Importance score: {importance_score:.4f}\")\n",
    "        if importance_score > 0:\n",
    "            channel_idx = int(channel_idx)\n",
    "            layer.weight[channel_idx, ...] = 0\n",
    "            if layer.bias is not None:\n",
    "                layer.bias[channel_idx] = 0\n",
    "            removed_features.append(channel_idx)\n",
    "\n",
    "    # Evaluate model with feature maps removed\n",
    "    new_predictions = get_predictions(model, dataloader, device)\n",
    "    new_regression_errors = get_regression_errors(new_predictions)\n",
    "    new_quality_rmse = get_rmse(new_regression_errors)\n",
    "\n",
    "    # Save the pruned model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # Restore original weights for future use\n",
    "    layer.weight.data.copy_(original_weights)\n",
    "    if layer.bias is not None:\n",
    "        layer.bias.data.copy_(original_bias)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'removed_features': removed_features,\n",
    "        'baseline_rmse': quality_rmse,\n",
    "        'final_rmse': new_quality_rmse,\n",
    "        'improvement': quality_rmse - new_quality_rmse,\n",
    "        'reduction_percentage': (len(removed_features)/len(sorted_importance_scores))*100\n",
    "    }\n",
    "\n",
    "def remove_channels(model,device,layer_name,channels_indexes)->QualityPredictor:\n",
    "    \"\"\"\n",
    "    Remove channels, using an index list, from a convolutional layer in a model.\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        device: Device to run the model on (cuda/cpu)\n",
    "        layer_name: Name of the layer to optimize\n",
    "        channels_indexes: List of channel indexes to remove\n",
    "        \n",
    "    Returns:\n",
    "        The pruned model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Get the target layer\n",
    "    dict_modules = dict(model.named_modules())\n",
    "    layer = dict_modules[layer_name]\n",
    "        \n",
    "    # Zero out the specified channels\n",
    "    for channel_idx in channels_indexes:\n",
    "        layer.weight[channel_idx, ...] = 0\n",
    "        if layer.bias is not None:\n",
    "            layer.bias[channel_idx] = 0\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of diffrent models using different pruning techniques\n",
    "\n",
    "- Deletion of models is due to make sure that im not using the same model again and again (first draft, not sure if im correctlly restoring weights in each pruning technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1181481/4238824482.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  base_model.load_state_dict(torch.load('Models/VGG-16_quality_finetuned.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality baseline RMSE: 11.1237\n",
      "Feature map 0: Importance score: 0.0000\n",
      "Feature map 1: Importance score: 0.0000\n",
      "Feature map 2: Importance score: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m base_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      9\u001b[0m base_model\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 11\u001b[0m sorted_importance_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_feature_map_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLAYER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRanking_arrays/quality_importance_scores.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, sorted_importance_scores)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m base_model\n",
      "Cell \u001b[0;32mIn[9], line 38\u001b[0m, in \u001b[0;36mcompute_feature_map_importance\u001b[0;34m(model, dataloader, device, layer_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m     layer\u001b[38;5;241m.\u001b[39mbias[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Get predictions with the pruned feature map\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m pruned_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m pruned_regression_errors \u001b[38;5;241m=\u001b[39m get_regression_errors(pruned_predictions)\n\u001b[1;32m     40\u001b[0m baseline_quality_rmse \u001b[38;5;241m=\u001b[39m get_rmse(pruned_regression_errors)\n",
      "Cell \u001b[0;32mIn[6], line 105\u001b[0m, in \u001b[0;36mget_predictions\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m    102\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient calculation\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m, in \u001b[0;36mImageQualityDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     32\u001b[0m img_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m3\u001b[39m])  \u001b[38;5;66;03m# image_path column\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m quality \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Quality column\u001b[39;00m\n\u001b[1;32m     35\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([quality], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.11/site-packages/PIL/Image.py:941\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert\u001b[39m(\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    891\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m     colors: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m    896\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image:\n\u001b[1;32m    897\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 941\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.11/site-packages/PIL/ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LAYER to prune\n",
    "LAYER = 'features.28'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# Base model for importance score computation\n",
    "base_model = QualityPredictor()\n",
    "base_model.load_state_dict(torch.load('Models/VGG-16_quality_finetuned.pth'))\n",
    "base_model.eval()\n",
    "base_model.to(DEVICE)\n",
    "\n",
    "sorted_importance_scores = compute_feature_map_importance(base_model, train_dataloader, DEVICE, LAYER)\n",
    "np.save('Ranking_arrays/quality_importance_scores.npy', sorted_importance_scores)\n",
    "del base_model\n",
    "\n",
    "# Model for negative impact feature maps removal\n",
    "negative_impact_model = QualityPredictor()\n",
    "negative_impact_model.load_state_dict(torch.load('Models/VGG-16_quality_finetuned.pth'))\n",
    "negative_impact_model.eval()\n",
    "negative_impact_model.to(DEVICE)\n",
    "\n",
    "negative_impact_subset = remove_negative_impact_feature_maps(negative_impact_model, train_dataloader, DEVICE, LAYER, sorted_importance_scores, model_path='Models/quality_negative_impact_pruned_model.pth')\n",
    "\n",
    "del negative_impact_model\n",
    "\n",
    "\n",
    "# Model for noisy feature maps removal\n",
    "noisy_pruning_model = QualityPredictor()\n",
    "noisy_pruning_model.load_state_dict(torch.load('Models/VGG-16_quality_finetuned.pth'))\n",
    "noisy_pruning_model.eval()\n",
    "noisy_pruning_model.to(DEVICE)\n",
    "\n",
    "noisy_optimal_subset = remove_noisy_feature_maps(noisy_pruning_model, train_dataloader, DEVICE, LAYER, sorted_importance_scores, model_path='Models/quality_noise_out_pruned_model.pth')\n",
    "\n",
    "del noisy_pruning_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with already saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = 'Models/VGG-16_quality_finetuned.pth'\n",
    "NEGATIVE_IMPACT_PRUNED_MODEL_PATH = 'Models/quality_negative_impact_pruned_model.pth'\n",
    "\n",
    "base_model = QualityPredictor()\n",
    "base_model.load_state_dict(torch.load(BASE_MODEL, weights_only=True))\n",
    "\n",
    "negative_impact_pruned_model = QualityPredictor()\n",
    "negative_impact_pruned_model.load_state_dict(torch.load(NEGATIVE_IMPACT_PRUNED_MODEL_PATH,weights_only=True))\n",
    "\n",
    "noisy_optimal_subset = QualityPredictor()\n",
    "noisy_optimal_subset.load_state_dict(torch.load('Models/quality_noise_out_pruned_model.pth',weights_only=True))\n",
    "# Testing\n",
    "\n",
    "# Test the baseline model\n",
    "print(\"Testing the baseline model\")\n",
    "test_model(base_model, test_dataloader, criterion, device)\n",
    "print(\"------------------\")\n",
    "\n",
    "# test the negative impact pruned model\n",
    "print(\"Testing the negative impact pruned model\")\n",
    "test_model(negative_impact_pruned_model, test_dataloader, criterion, device)\n",
    "print(\"------------------\")\n",
    "\n",
    "# test the noisy optimal subset pruned model\n",
    "print(\"Testing the noisy optimal subset pruned model\")\n",
    "test_model(noisy_optimal_subset, test_dataloader, criterion, device)\n",
    "print(\"------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Aanalysis - Comparing the models zeroed out weights & Correlations between the models predicitons and ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-out weights analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that extract the indices of the zeroed out feature maps in a convolutional layer\n",
    "\n",
    "def get_zeroed_feature_maps(model, layer_name):\n",
    "    \"\"\"\n",
    "    Get the indices of the zeroed out feature maps in a convolutional layer.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        layer_name (str): The name of the convolutional layer.\n",
    "\n",
    "    Returns:\n",
    "        list: The indices of the zeroed out feature maps.\n",
    "    \"\"\"\n",
    "    dict_modules = dict(model.named_modules())\n",
    "    layer = dict_modules[layer_name]\n",
    "    zeroed_feature_maps = []\n",
    "\n",
    "    for i, weight in enumerate(layer.weight):\n",
    "        if torch.all(weight == 0):\n",
    "            zeroed_feature_maps.append(i)\n",
    "    zeroed_feature_maps.sort()\n",
    "\n",
    "    num_zeroed = len(zeroed_feature_maps)\n",
    "\n",
    "    return zeroed_feature_maps, num_zeroed\n",
    "\n",
    "# Get the zeroed out feature maps in the 'features.28' layer of the noisy pruned model\n",
    "_, noisy_num_zeroed = get_zeroed_feature_maps(noisy_pruned_model, 'features.28')\n",
    "\n",
    "# Get the zeroed out feature maps in the 'features.28' layer of the best subset pruned model\n",
    "_, best_subset_num_zeroed = get_zeroed_feature_maps(best_subset_pruned_model, 'features.28')\n",
    "\n",
    "# Get the zeroed out feature maps in the 'features.28' layer of the negative impact pruned model\n",
    "_, negative_impact_num_zeroed = get_zeroed_feature_maps(negative_impact_pruned_model, 'features.28')\n",
    "\n",
    "print(f\"Noisy pruned model: {noisy_num_zeroed} zeroed out feature maps\")\n",
    "print(f\"Best subset pruned model: {best_subset_num_zeroed} zeroed out feature maps\")\n",
    "print(f\"Negative impact pruned model: {negative_impact_num_zeroed} zeroed out feature maps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test RSA on the models (baseline and pruned models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the models for RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_MODEL_NAME = 'Models/VGG-16_quality_finetuned.pth'\n",
    "NOISY_PRUNED_MODEL_PATH = 'Models/quality_noise_out_pruned_model.pth'\n",
    "NEGATIVE_IMPACT_PRUNED_MODEL_PATH = 'Models/quality_negative_impact_pruned_model.pth'\n",
    "\n",
    "baseline_model = qualityPredictor()\n",
    "baseline_model.load_state_dict(torch.load(BASELINE_MODEL_NAME, weights_only=True))\n",
    "\n",
    "noisy_pruned_model = qualityPredictor()\n",
    "noisy_pruned_model.load_state_dict(torch.load(NOISY_PRUNED_MODEL_PATH, weights_only=True))\n",
    "\n",
    "negative_impact_pruned_model = qualityPredictor()\n",
    "negative_impact_pruned_model.load_state_dict(torch.load(NEGATIVE_IMPACT_PRUNED_MODEL_PATH,weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeatureMapHook:\n",
    "    \"\"\"Hook to extract feature maps from neural network layers.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_maps = []\n",
    "    \n",
    "    def __call__(self, module, input, output):\n",
    "        # Detach from computation graph and move to CPU\n",
    "        self.feature_maps.append(output.detach().cpu())\n",
    "\n",
    "def get_feature_maps(model, dataloader, layer_name, device):\n",
    "    \"\"\"\n",
    "    Extracts the feature maps of a specific layer from a model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        dataloader (DataLoader): DataLoader for evaluation.\n",
    "        layer_name (str): The name of the layer to extract feature maps from.\n",
    "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The feature maps as a numpy array with shape (240, num_features).\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Register a hook to extract feature maps\n",
    "    hook = FeatureMapHook()\n",
    "    target_layer = dict(model.named_modules())[layer_name]\n",
    "    hook_handle = target_layer.register_forward_hook(hook)\n",
    "    \n",
    "    # Forward pass to extract feature maps from the dataloader\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            model(inputs)\n",
    "\n",
    "    # Remove the hook\n",
    "    hook_handle.remove()\n",
    "    \n",
    "    # Process the feature maps to get the desired shape\n",
    "    all_features = []\n",
    "    \n",
    "    for batch_features in hook.feature_maps:\n",
    "        # Handle different possible output formats (accommodate different layer types)\n",
    "        if len(batch_features.shape) == 4:  # Conv layers: [batch_size, channels, height, width]\n",
    "            batch_size, channels, height, width = batch_features.shape\n",
    "            # Flatten spatial dimensions and create one feature vector per sample\n",
    "            batch_features = batch_features.reshape(batch_size, channels * height * width)\n",
    "        elif len(batch_features.shape) == 2:  # Linear layers: [batch_size, features]\n",
    "            pass  # Already in the right format\n",
    "        \n",
    "        # Add batch features to our collection\n",
    "        all_features.append(batch_features)\n",
    "    \n",
    "    # Concatenate all batches and convert to numpy\n",
    "    features_tensor = torch.cat(all_features, dim=0)\n",
    "    \n",
    "    # Ensure we have exactly the number of samples we expect in the dataloader \n",
    "    assert features_tensor.shape[0] == len(dataloader.dataset) \n",
    "    \n",
    "    # Convert to numpy array\n",
    "    features_array = features_tensor.numpy()\n",
    "    \n",
    "    return features_array\n",
    "def compute_similarity_matrix(features):\n",
    "    \"\"\"\n",
    "    Compute a similarity matrix from feature embeddings.\n",
    "    Works with both convolutional features (4D) and FC features (2D).\n",
    "    \n",
    "    Args:\n",
    "        features: numpy array - either shape (n_samples, n_channels, height, width)\n",
    "                 or shape (n_samples, n_features)\n",
    "        \n",
    "    Returns:\n",
    "        similarity_matrix: numpy array of shape (n_samples, n_samples)\n",
    "    \"\"\"\n",
    "    # Check the dimensionality of features\n",
    "    n_samples = features.shape[0]\n",
    "    \n",
    "    # If features are from convolutional layer (4D), reshape to 2D\n",
    "    if len(features.shape) == 4:\n",
    "        features_flat = features.reshape(n_samples, -1)\n",
    "    else:\n",
    "        # Features are already 2D (from FC layer)\n",
    "        features_flat = features\n",
    "    \n",
    "    # Compute cosine similarity between all pairs\n",
    "    similarity_matrix = cosine_similarity(features_flat)\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "def compute_quality_difference_matrix(quality_scores):\n",
    "    \"\"\"\n",
    "    Compute a matrix of quality differences between all pairs of samples.\n",
    "    \n",
    "    Args:\n",
    "        quality_scores: numpy array of shape (n_samples,) containing quality scores\n",
    "        \n",
    "    Returns:\n",
    "        difference_matrix: numpy array of shape (n_samples, n_samples)\n",
    "    \"\"\"\n",
    "    n_samples = quality_scores.shape[0]\n",
    "    difference_matrix = np.zeros((n_samples, n_samples))\n",
    "    \n",
    "    # Compute absolute differences between all pairs\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            difference_matrix[i, j] = abs(quality_scores[i] - quality_scores[j])\n",
    "            \n",
    "    return difference_matrix\n",
    "\n",
    "def get_upper_triangle(matrix):\n",
    "    \"\"\"\n",
    "    Extract the upper triangle of a matrix (excluding diagonal).\n",
    "    \n",
    "    Args:\n",
    "        matrix: numpy array of shape (n, n)\n",
    "        \n",
    "    Returns:\n",
    "        upper_triangle: flattened upper triangle values\n",
    "    \"\"\"\n",
    "    indices = np.triu_indices_from(matrix, k=1)\n",
    "    return matrix[indices]\n",
    "\n",
    "def calculate_fit(similarity_matrix, quality_diff_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the fit between similarity and quality difference matrices.\n",
    "    \n",
    "    Args:\n",
    "        similarity_matrix: numpy array of shape (n_samples, n_samples)\n",
    "        quality_diff_matrix: numpy array of shape (n_samples, n_samples)\n",
    "        \n",
    "    Returns:\n",
    "        correlation: Spearman correlation coefficient between the matrices\n",
    "        p_value: p-value of the correlation\n",
    "    \"\"\"\n",
    "    # Extract upper triangles (excluding diagonal)\n",
    "    sim_upper = get_upper_triangle(similarity_matrix)\n",
    "    qual_upper = get_upper_triangle(quality_diff_matrix)\n",
    "    \n",
    "    # Compute correlation (negative since higher similarity should correspond to lower difference)\n",
    "    correlation, p_value = spearmanr(sim_upper, qual_upper)\n",
    "    \n",
    "    # We're expecting a negative correlation (higher similarity → lower quality difference)\n",
    "    # so we return the negative correlation value for easier interpretation\n",
    "    return -correlation, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature maps\n",
    "baseline_features = get_feature_maps(baseline_model, test_dataloader, 'fc1.3', device)\n",
    "\n",
    "noisy_pruned_features = get_feature_maps(noisy_pruned_model, test_dataloader, 'fc1.3', device)\n",
    "\n",
    "negative_impact_features = get_feature_maps(negative_impact_pruned_model, test_dataloader, 'fc1.3', device)\n",
    "\n",
    "# Extract quality scores\n",
    "auth_scores_list = []\n",
    "with torch.no_grad():\n",
    "\tfor _, labels in test_dataloader:\n",
    "\t\tauth_scores_list.append(labels[:, 0])  # First column contains auth scores\n",
    "q_scores = torch.cat(auth_scores_list).numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity matrices\n",
    "baseline_similarity = compute_similarity_matrix(baseline_features)\n",
    "noisy_similarity = compute_similarity_matrix(noisy_pruned_features)\n",
    "negative_impact_similarity = compute_similarity_matrix(negative_impact_features)\n",
    "\n",
    "# Compute quality difference matrices\n",
    "quality_diff_matrix = compute_quality_difference_matrix(q_scores)\n",
    "\n",
    "# Calculate fit between similarity and quality difference matrices\n",
    "baseline_fit = calculate_fit(baseline_similarity, quality_diff_matrix)\n",
    "noisy_fit = calculate_fit(noisy_similarity, quality_diff_matrix)\n",
    "negative_impact_fit = calculate_fit(negative_impact_similarity, quality_diff_matrix)\n",
    "\n",
    "print(\"Baseline Model Fit:\")\n",
    "print(f\"Correlation: {baseline_fit[0]:.4f}\")\n",
    "print(\"------------------\")\n",
    "print(\"RSME Noise-out Pruned Model Fit:\")\n",
    "print(f\"Correlation: {noisy_fit[0]:.4f}\")\n",
    "print(\"------------------\")\n",
    "print(\"RSME Negative Impact Pruned Model Fit:\")\n",
    "print(f\"Correlation: {negative_impact_fit[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
